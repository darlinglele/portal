<p>
文本聚类是一个很常用的非监督学习的应用，把特征相似的文本归为一类。 聚类拥有广大的用途，新闻台面对一堆五花八门未经归类的新闻内容时，通过聚类就可以按照新闻内容把内容相似的归成一个类别，体育类新闻将被对称一类，财经类则分到另外一类。

特征向量

向量空间模型的基本思想是文本向量化，d =[w1,w2..w]T ，特征向量的每个维度代表一个特征（单词），w是个标量，代表该维度特征的权重。 如此，文本d就是欧氏空间中的一个向量。


文本库 =
    [“这是第一个文档，就是这些”，“这是第二个文档，还是这些”，“这是第三个文档，文档“”]

假设文档库中的所有词(需要中文分词)都作为特征词，那么特征向量的维度是。
假定维度是文本库中所有出现的词，[这是，第一，第二，第三，个，文档，就是，还是，这些]T
文本的向量化表示                    [1   1  0    0  1   1      1      0  1]T
文本库的矩阵表示是
[这是，第一，第二，第三，个，文档，就是，还是，这些]T
[1      1   0       0   1   1      1      0     1]T
[1      0   1       0   1      1        0         1     1]T
[1      0       0       1   1      2        0         1         1]T

一种简单的文本特征表示是把单词的频度为了该维度的权重,权重越大，对整个文本的影响就越大。

矩阵的一行表示一个文本的特征向量，维度是文本库中所有出现的词。

这种方法最为简单，因为它基于一种假设，假设每个特征词对区别文本的贡献是相等的，这是一个就很不合理的：

直观上，我们会发现一些文本中会频繁使用的词语，比如“我们”，“你们”，如果使用TF计数作为w，权重很大，但由于这些词在任何类型主题中都经常出现，对文本的归类区别的贡献很小。还有一些词只会出现在特定主题的文本里，例如“图灵机”， 这个词很可能出现在计算机主题的文本里，不太可能出现体育、时政类的主题的文本里， 因此它区分能力比较好。基于此，一种更好的文本特征是TF-IDF。
TF-IDF 则要Term  frequency * Invert document frequency  IDF= log(D/Di)  ， 

TF-IDF特征向量构成的matrix 可以通过原始的 matrix 经过计算而来，

应当注意的是， 在实际应用中文本库很大，特征向量的维度将会非常高，但是对于每个文本来说，大部分维度的权值为0， 特征向量中只有少数非0值。
因此文本库构成的文本特征矩阵是个稀疏矩阵，一般的矩阵表示将浪费很多的空间，对此Python中的Scipy.sparse专门处理这种稀疏数据，节省内存空间。



降低维度：
    协方差：

文本距离：
    此时可以把文本D= {d1,d2..dn } 是空间中的向量（或者点），那么文本特征可以映射到欧氏集合空间中各个向量（或者点）， 这样我们就把一个文本相似度这个抽象概念转化成一个我们熟悉的几何模型， 通过计算两个向量的余弦值、或者计算两个点的空间距离，就可以知道两个文本之间的距离。
cos(theta) = A*B/|A||B|
sqart(E(a-b)^2)  


聚类算法 K均值算法

</p>

<h4>实现的思路：</h4>
